{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f64c24",
   "metadata": {},
   "source": [
    "## Prior to this notebook I completed the following:\n",
    "\n",
    "### Task 1:\n",
    "\n",
    "1: Created a new, empty GBQ dataset called msba_wedge\n",
    "\n",
    "2: Downloaded a zip file of cleaned Wedge data from Moodle\n",
    "\n",
    "3: Decompressed and uploaded the cleaned Wedge files to Google Storage Cloud using the Storage Cloud UI.\n",
    "\n",
    "4: Connected to Google Storage Cloud from Google Big Query, reading in all 53 transaction files into a single transaction table within my msba_wedge dataset.\n",
    "\n",
    "5: Applied Google's auto schema settings to determine field types and then validated them in GBQ's schema view.\n",
    "\n",
    "\n",
    "## This Notebook handles the following tasks:\n",
    "\n",
    "### Task 2:\n",
    "1: Use Python to connect to my GBQ instance\n",
    "    \n",
    "2: Build a list of owners\n",
    "        \n",
    "3: Take a sample of the owners\n",
    "\n",
    "4: Build a dataframe of all records for the sample of owners\n",
    "\n",
    "5: Write that data to a .txt file\n",
    "\n",
    "\n",
    "### Task 3:\n",
    "\n",
    "6. Use Pandas Dataframes and SQL to build three summary tables:\n",
    "\n",
    "    - Sales by Date and Hour\n",
    "    - Sales by Owner by Year and Month\n",
    "    - Sales by Product Description by Year and Month. \n",
    "\n",
    "\n",
    "7. Build a single SQLite Database containing the three summary files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39164062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pip install --upgrade google-cloud-BigQuery\n",
    "# import random is to support random owner sample\n",
    "# Sqlalchemy allows me to read gbq data into a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import sqlalchemy\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# establishing google credentials and creating engine and client variables to use with sqlalchemy\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('C:\\\\Users\\\\dakot\\\\Desktop\\\\Repo\\\\du_wedge_project\\\\ADA_2022_Wedge_Umbel\\\\dakota-umt-msba-dc288f16c43e.json')\n",
    "project_id = 'dakota-umt-msba'\n",
    "\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "from config import bigquery_uri\n",
    "engine = create_engine(bigquery_uri,credentials_path ='C:\\\\Users\\\\dakot\\\\Desktop\\\\Repo\\\\du_wedge_project\\\\ADA_2022_Wedge_Umbel\\\\dakota-umt-msba-dc288f16c43e.json')\n",
    "client = bigquery.Client(credentials = credentials,project = project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d7c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Query that Generates list of Distinct Owners\n",
    "\n",
    "owners = (\"\"\"\n",
    "       SELECT DISTINCT(card_no)\n",
    "       FROM msba_wedge.Wedge_Transactions \n",
    "       WHERE card_no <> 3\"\"\")\n",
    "\n",
    "\n",
    "# Stores unique owners in a variable called results\n",
    "\n",
    "results = client.query(owners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54bf6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty LIST of owners\n",
    "\n",
    "owners = []\n",
    "\n",
    "\n",
    "# Populating owner list\n",
    "\n",
    "for row in results:\n",
    "    owners.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41eee02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a list of 500 random owners. This sample size outputs between 200MB and 250MB of data.\n",
    "\n",
    "sample_owners = random.sample(owners,500)\n",
    "\n",
    "\n",
    "# Turns list into Tuple so that I can use it as a reference in my next SQL statement's WHERE clause\n",
    "# This gives a dynamic random sample of users rather than hardcoding a static list of users\n",
    "\n",
    "sample_owners_tuple = tuple(sample_owners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b0cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning query to a variable allows for updates to \"WHERE/IN\" each time the random sample is updated\n",
    "sample_owner_query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM dakota-umt-msba.msba_wedge.Wedge_Transactions \n",
    "    WHERE card_no IN {};\"\"\".format(sample_owners_tuple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f638d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing SQL statment that lists ALL records for sample of owners and storing it to dataframe\n",
    "df = pd.read_sql_query(sample_owner_query, con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82166f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to .txt file in current working directory\n",
    "df.to_csv('sample_owner_data.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d216b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following summary tables will populate a SQLite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a53c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Summary Table 1 - Sales by Date and Hour\n",
    "# I included total return/void spend and items \n",
    "# because the total spend was confusing to me without also seeing these datapoints\n",
    "\n",
    "sales_date_hour_query = \"\"\"\n",
    "SELECT \n",
    "  CAST(datetime AS date) AS date\n",
    ", EXTRACT(HOUR FROM datetime) AS hour\n",
    ", COUNT(DISTINCT(trans_no)) as total_transactions\n",
    ", ROUND(SUM(total),2) AS total_net_spend\n",
    ", ROUND(SUM(CASE WHEN total >=  0 THEN total END),2) AS total_non_negative_spend\n",
    ", ROUND(SUM(CASE WHEN total < 0 THEN total END),2) AS total_negative_spend\n",
    ", COUNT(CASE WHEN trans_status IS NULL \n",
    "        OR trans_status = \" \"\n",
    "        THEN 1 END) AS total_items_sold\n",
    ", COUNT(CASE WHEN trans_status IS NOT NULL OR trans_status != \" \"\n",
    "        THEN 1 END) AS total_items_returned_voided_or_other\n",
    " FROM `dakota-umt-msba.msba_wedge.Wedge_Transactions`\n",
    " GROUP BY date, hour\n",
    " ORDER BY date ASC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6088ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting summary table 1 to dataframe\n",
    "df_summary_table_1 = pd.read_sql_query(sales_date_hour_query, con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9073e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Summary Table 2 - Sales by Owner Year and Month\n",
    "# I included negative and positive spend in addition to net spend  \n",
    "# because the total spend and transactions was confusing to me without also seeing these datapoints.\n",
    "\n",
    "owner_sales_year_month_query = \"\"\"\n",
    "SELECT \n",
    "  card_no AS card_no\n",
    ", EXTRACT(YEAR FROM datetime) AS year\n",
    ", EXTRACT(MONTH FROM datetime) AS month\n",
    ", COUNT(DISTINCT(trans_no)) as total_transactions\n",
    ", ROUND(SUM(total),2) AS total_net_spend\n",
    ", ROUND(SUM(CASE WHEN total >=  0 THEN total END),2) AS total_non_negative_spend\n",
    ", ROUND(SUM(CASE WHEN total < 0 THEN total END),2) AS total_negative_spend\n",
    ", COUNT(CASE WHEN trans_status IS NULL \n",
    "        OR trans_status = \" \"\n",
    "        THEN 1 END) AS total_items_sold\n",
    ", COUNT(CASE WHEN trans_status IS NOT NULL OR trans_status != \" \"\n",
    "        THEN 1 END) AS total_items_returned_voided_or_other\n",
    " FROM `dakota-umt-msba.msba_wedge.Wedge_Transactions`\n",
    " GROUP BY card_no, year,month\n",
    " ORDER BY total_net_spend DESC\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944a0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting summary table 2 to dataframe\n",
    "df_summary_table_2 = pd.read_sql_query(owner_sales_year_month_query, con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7710df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Summary Table 3 - product sales by year and month\n",
    "# I included negative and positive spend in addition to net spend  \n",
    "# because the total spend and transactions was confusing to me without also seeing these datapoints.\n",
    "\n",
    "product_sales_year_month_query = \"\"\"\n",
    "\n",
    "SELECT\n",
    " tran.upc AS upc\n",
    ",tran.description AS description\n",
    ",tran.department AS department_number\n",
    ",dept.dept_name AS department_name\n",
    ", EXTRACT(YEAR FROM tran.datetime) AS year\n",
    ", EXTRACT(MONTH FROM tran.datetime) AS month\n",
    ", COUNT(DISTINCT(tran.trans_no)) as total_transactions\n",
    ", ROUND(SUM(tran.total),2) AS total_net_spend\n",
    ", ROUND(SUM(CASE WHEN tran.total >=  0 THEN tran.total END),2) AS total_non_negative_spend\n",
    ", ROUND(SUM(CASE WHEN tran.total < 0 THEN tran.total END),2) AS total_negative_spend\n",
    ", COUNT(CASE WHEN tran.trans_status IS NULL \n",
    "        OR tran.trans_status = \" \"\n",
    "        THEN 1 END) AS total_items_sold\n",
    ", COUNT(CASE WHEN tran.trans_status IS NOT NULL OR tran.trans_status != \" \"\n",
    "        THEN 1 END) AS total_items_returned_voided_or_other\n",
    " FROM `dakota-umt-msba.msba_wedge.Wedge_Transactions` tran\n",
    " JOIN `dakota-umt-msba.msba_wedge.dept_lookup` dept ON dept.department = tran.department\n",
    " GROUP BY upc,description,department_number,department_name,year,month\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a763d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting summary table 3 to dataframe\n",
    "df_summary_table_3 = pd.read_sql_query(product_sales_year_month_query, con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b09b7636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 created successfully\n",
      "Table 2 created successfully\n",
      "Table 3 created successfully\n"
     ]
    }
   ],
   "source": [
    "# The following code creates a SQLite db containing the 3 summary tables from above\n",
    "\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "# Creating the database file in the current working directory\n",
    "create_connection = (r\"wedge_summary.db\")\n",
    "\n",
    "# Connecting to database\n",
    "conn = sqlite3.connect(\"wedge_summary.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "# Dropping tables if they already exist\n",
    "drop_table1 = \"\"\" DROP TABLE IF EXISTS sales_date_hour \"\"\"\n",
    "c.execute(drop_table1)\n",
    "\n",
    "drop_table2 = \"\"\" DROP TABLE IF EXISTS owner_sales_year_month \"\"\"\n",
    "c.execute(drop_table2)\n",
    "\n",
    "drop_table3 = \"\"\" DROP TABLE IF EXISTS product_sales_year_month \"\"\"\n",
    "c.execute(drop_table3)\n",
    "\n",
    "# Creating empty tables and defining schemas\n",
    "t1 = \"\"\" CREATE TABLE sales_date_hour(\n",
    "                      date TEXT\n",
    "                    , hour INTEGER\n",
    "                    ,total_transactions INTEGER\n",
    "                    ,total_net_spend NUMERIC\n",
    "                    ,total_non_negative_spend NUMERIC\n",
    "                    ,total_negative_spend NUMERIC\n",
    "                    ,total_items_sold INTEGER\n",
    "                    ,total_items_returned_voided_or_other INTEGER\n",
    "                    )\"\"\"\n",
    "c.execute(t1)\n",
    "print(\"Table 1 created successfully\")\n",
    "\n",
    "t2 = \"\"\" CREATE TABLE owner_sales_year_month(\n",
    "                      card_no TEXT\n",
    "                    , year INTEGER\n",
    "                    , month INTEGER\n",
    "                    ,total_transactions INTEGER\n",
    "                    ,total_net_spend NUMERIC\n",
    "                    ,total_non_negative_spend NUMERIC\n",
    "                    ,total_negative_spend NUMERIC\n",
    "                    ,total_items_sold INTEGER\n",
    "                    ,total_items_returned_voided_or_other INTEGER\n",
    "                    )\"\"\"\n",
    "c.execute(t2)\n",
    "print(\"Table 2 created successfully\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t3 = \"\"\" CREATE TABLE product_sales_year_month(\n",
    "                      upc TEXT\n",
    "                    , description TEXT\n",
    "                    , department_number INTEGER\n",
    "                    , department_name TEXT\n",
    "                    , year INTEGER\n",
    "                    , month INTEGER\n",
    "                    ,total_transactions INTEGER\n",
    "                    ,total_net_spend NUMERIC\n",
    "                    ,total_non_negative_spend NUMERIC\n",
    "                    ,total_negative_spend NUMERIC\n",
    "                    ,total_items_sold INTEGER\n",
    "                    ,total_items_returned_voided_or_other INTEGER\n",
    "                    )\"\"\"\n",
    "c.execute(t3)\n",
    "print(\"Table 3 created successfully\")\n",
    "\n",
    "\n",
    "\n",
    "# write the data to a sqlite table\n",
    "df_summary_table_1.to_sql('sales_date_hour', conn, if_exists='replace', index = False)\n",
    "\n",
    "df_summary_table_2.to_sql('owner_sales_year_month', conn, if_exists='replace', index = False)\n",
    "\n",
    "df_summary_table_3.to_sql('product_sales_year_month', conn, if_exists='replace', index = False)\n",
    "\n",
    "\n",
    "\n",
    "#commiting changines and closing connection\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
